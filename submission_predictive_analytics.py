# -*- coding: utf-8 -*-
"""Submission_Predictive_Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1deJdq3U4n4S5jCw_iOLEzcLQ4y2s3dxR

# Proyek Predictive Analytics: [Flood Prediction Dataset](https://www.kaggle.com/datasets/naiyakhalid/flood-prediction-dataset)
- **Nama:** Nafa Khairunnisa
- **Email:** nkhairunn2412@gmail.com
- **ID Dicoding:** nafa-khairunnisa

## Import Libraries
"""

!pip install scikeras

# Commented out IPython magic to ensure Python compatibility.
# Library yang sering digunakan
import os
import shutil
from google.colab import drive
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

# Libraries untuk pembangunan model
import tensorflow as tf
from sklearn.preprocessing import RobustScaler
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor
from sklearn.neural_network import MLPRegressor
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input, LeakyReLU, Dropout
from tensorflow.keras.activations import relu, tanh
from scikeras.wrappers import KerasRegressor
from sklearn.model_selection import cross_val_score, KFold
from sklearn.metrics import make_scorer, mean_squared_error, r2_score

"""## Data Loading"""

# Mount Google Drive
drive.mount('/content/drive')

# Cek apakah file tersedia
!ls /content/drive/MyDrive/kaggle/

!mkdir -p ~/.kaggle
!cp /content/drive/MyDrive/kaggle/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Membuat folder .kaggle
os.makedirs("/root/.kaggle", exist_ok=True)

# Memindahkan kaggle.json dari folder di Google Drive ke folder .kaggle
shutil.move('/content/drive/MyDrive/kaggle/kaggle.json', '/root/.kaggle/kaggle.json')

# Mengubah permission agar hanya bisa dibaca oleh user
os.chmod('/root/.kaggle/kaggle.json', 600)

# Download dataset dari Kaggle
!kaggle datasets download -d naiyakhalid/flood-prediction-dataset

# Unzip file dataset
!unzip flood-prediction-dataset.zip

# Load the dataset
flood_df = pd.read_csv('/content/flood.csv')
flood_df.head()

"""## Data Understanding dengan Exploratory Data Analysis (EDA)

### Deskripsi Variabel
"""

flood_df.info()

"""**Insights**:

- Dataset yang digunakan memiliki 21 kolom yang diantaranya 20 fitur dan 1 label target.
- Label target yaitu FloodProbability.
- Semua fitur memiliki tipe data integer, sedangkan label target memiliki tipe data float64.
- Jumlah data keseluruhan ada 50000 sampel dan tidak ada nilai NaN.
"""

flood_df.describe()

"""**Insights**:
- Mean semua variabel sekitar 5.
- Standar deviasi sekitar 2.2-an.
- Semua fitur dalam skala yang hampir sama, termasuk FloodProbability (range 0.285–0.725).
"""

flood_df.loc[(flood_df['MonsoonIntensity']==0)]

"""**Insights**:

- Berdasarkan salah satu fitur (MonsoonIntensity), tidak ada baris di mana semua fitur bernilai 0 secara bersamaan. Artinya, tidak ada data yang perlu dihapus.

### Cek missing value
"""

flood_df.isna().sum()

"""### Cek duplikasi data"""

flood_df.duplicated().sum()

"""### Cek outliers"""

# Membuat boxplot untuk setiap fitur numerik
plt.figure(figsize=(20, 15))
for i, feature in enumerate(flood_df, 1):
    plt.subplot(5, 5, i)
    sns.boxplot(data=flood_df, x=feature)
    plt.title(f'Boxplot for {feature}')

plt.tight_layout()
plt.show()

"""**Insights**:

- Berdasarkan boxplot tersebut, tiap variabel memiliki outliers yang bervariasi.
- Beberapa variabel yang memiliki outliers ekstrem yaitu TopographyDrainage, Encroachments, WetlandLoss, dan PopulationScore.
- Outliers label target (FloodProbability) memiliki distribusi yang cukup sempit (sekitar 0.3–0.65) tanpa outlier ekstrem.

### Univariate analysis
"""

flood_df.hist(bins=50, figsize=(15,12))
plt.show()

"""**Insights**:

- Mayoritas fitur punya distribusi condong kanan (right-skewed).
- Sebagian fitur terdistribusi normal.
- Skor target berkisar antara 0.3 sampai 0.7.
- Ada dua puncak (peaks), artinya kemungkinan besar dataset ini memiliki dua kelompok besar dalam data.

### Multivariate analysis
"""

# Correlation matrix
plt.figure(figsize=(10, 8))
correlation_matrix = flood_df.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Correlation Matrix untuk Fitur Numerik ", size=20)

"""**Insights**:

- Semua fitur korelasi positif lemah terhadap label target (FloodProbability) di kisaran 0.22 - 0.23. Artinya, semua fitur relevan dalam konteks ini karena kontribusinya terhadap FloodProbability cenderung merata.
- Korelasi antar fitur juga sangat rendah yang artinya tidak terjadi multikolinearitas tinggi.

## Data Preparation

### Normalisasi
"""

# Memisahkan kolom fitur dan target
X = flood_df.drop(columns=['FloodProbability'])  # fitur
y = flood_df['FloodProbability']  # target

# Scaling memakai RobustScaler
scaler = RobustScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

"""### Menangani outliers"""

# Penanganan outliers
# Winsorizing (clipping outlier ke persentil 1% dan 99%)
for col in X_scaled.columns:
    lower = X_scaled[col].quantile(0.01)
    upper = X_scaled[col].quantile(0.99)
    X_scaled[col] = X_scaled[col].clip(lower, upper)

# Menyimpan data hasil
X_ready = X_scaled.copy()

# Cek setelah penanganan outliers
sns.boxplot(data=X_ready)
plt.title("Boxplot After Winsorizing")
plt.show()

"""**Insights**:

- Berdasarkan boxplot tersebut, terdapat outliers yang tersisa tetapi masih dalam batas winsor.

### Feature Engineering
"""

# Menggabungkan fitur hasil penanganan outliers dan label target
df_gabungan = pd.concat([X_ready, y], axis=1)

# Menyalin isi df_gabungan ke df baru
df_preparation = df_gabungan.copy()

# Menggabungkan beberapa fitur menjadi satu dengan penjumlahan dan dibagi 2 (Agar nilainya agar tetap berada dalam skala yang sebanding dengan fitur-fitur aslinya.)
df_preparation['KeseluruhanKapasitasDrainase'] = (df_preparation['TopographyDrainage'] + df_preparation['DrainageSystems']) / 2

df_preparation['PengelolaanEndapanSungai'] = (df_preparation['Siltation'] + df_preparation['RiverManagement']) / 2

df_preparation['PengaruhBanjirPerkotaan'] = (df_preparation['PopulationScore'] + df_preparation['WetlandLoss']) / 2

df_preparation['DegradasiLahan'] = (df_preparation['Deforestation'] + df_preparation['AgriculturalPractices']) / 2

df_preparation['PengaruhIklimMuson'] = (df_preparation['MonsoonIntensity'] + df_preparation['ClimateChange']) / 2

df_preparation['RisikoUrbanisasiDanPendudukanLahan'] = (df_preparation['Urbanization'] + df_preparation['Encroachments']) / 2

df_preparation['DampakTataKelola'] = (df_preparation['IneffectiveDisasterPreparedness'] + df_preparation['PoliticalFactors']) / 2

df_preparation['KesiapanPerencanaanBencana'] = (df_preparation['InadequatePlanning'] + df_preparation['PoliticalFactors']) / 2

df_preparation['KualitasInfrastruktur'] = (df_preparation['DeterioratingInfrastructure'] + df_preparation['DrainageSystems']) / 2

df_preparation['RisikoWilayahPesisir'] = (df_preparation['CoastalVulnerability'] + df_preparation['WetlandLoss']) / 2

df_preparation['RisikoKemiringanDanAliranAir'] = (df_preparation['Landslides'] + df_preparation['Watersheds']) / 2

# Mengubah nama kolom DamsQuality dan FloodProbability ke dalam bahasa Indonesia
df_preparation.rename(columns={'DamsQuality': 'KualitasBendungan',
                   'FloodProbability': 'ProbabilitasBanjir'
                   }, inplace=True)

"""### Train-Test-Split

Mengingat dataset yang memiliki total 50000 sampel, untuk pembagian data ini akan diambil sebanyak 10% saja untuk data testing. Jadi, pembagian datanya yaitu 90% untuk training data dan 10% untuk testing data.
"""

# Memisahkan kolom fitur dan target
X = df_preparation.drop(columns=['ProbabilitasBanjir'])  # fitur
y = df_preparation['ProbabilitasBanjir']  # target

# Data splitting
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)

print(f'Total # of sample in whole dataset: {len(X)}')
print(f'Total # of sample in train dataset: {len(X_train)}')
print(f'Total # of sample in test dataset: {len(X_test)}')

"""## Modeling

### Linear Regression
"""

# Inisialisasi model Linear Regression
lr_model = LinearRegression()

# Training model Linear Regression
lr_model.fit(X_train, y_train)

# Prediksi pada data test
y_pred_lr = lr_model.predict(X_test)

"""### Gradient Booster (GBR)"""

# Inisialisasi model Gradient Boosting Regressor
gb_model = GradientBoostingRegressor(random_state=42)

# Training model Gradient Boosting
gb_model.fit(X_train, y_train)

# Prediksi pada data test
y_pred_gb = gb_model.predict(X_test)

"""### Artifical Neural Networks (ANN)"""

# Fungsi untuk membangun model ANN
def build_ann(activation_function='relu'):
    ann_model = Sequential()
    ann_model.add(Input(shape=(X_train.shape[1],)))  # Input layer 1 hidden  layer

    # Menambahkan hidden layer dengan fungsi aktivasi yang ditentukan
    if activation_function == 'leaky_relu':
        ann_model.add(Dense(10))  # 10 neuron
        ann_model.add(LeakyReLU(negative_slope=0.01))
    else:
        ann_model.add(Dense(10, activation=activation_function))  # Fungsi aktivasi sesuai parameter

    ann_model.add(Dropout(0.3))  # Dropout layer untuk menghindari overfitting

    ann_model.add(Dense(1, activation='linear'))  # Output layer dengan linear activation untuk regresi
    ann_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01), loss='mean_squared_error')
    return ann_model

# Fungsi aktivasi yang akan diuji
activation_functions = ['relu', 'tanh', 'leaky_relu']

results = {}

for activation in activation_functions:
    print(f"Training model dengan activation function: {activation}")

    # Membangun model menggunakan fungsi build_ann
    ann_model = KerasRegressor(model=build_ann, activation_function=activation, epochs=10, batch_size=32, verbose=0)

    # Melakukan training
    ann_model.fit(X_train, y_train)

    # Prediksi pada data test
    y_pred = ann_model.predict(X_test)

"""## Evaluasi Model

### MSE, RMSE, dan R²
"""

mse_lr = mean_squared_error(y_test, y_pred_lr)
rmse_lr = np.sqrt(mse_lr)
r2_lr = r2_score(y_test, y_pred_lr)

print("Linear Regression:")
print("  MSE:", mse_lr)
print("  RMSE:", rmse_lr)
print("  R2 :", r2_lr)

mse_gb = mean_squared_error(y_test, y_pred_gb)
rmse_gb = np.sqrt(mse_gb)
r2_gb = r2_score(y_test, y_pred_gb)

print("Boosting:")
print("  MSE:", mse_gb)
print("  RMSE:", rmse_gb)
print("  R2 :", r2_gb)

# Evaluasi model
print("Hasil Evaluasi untuk Semua Fungsi Aktivasi:")
for activation in activation_functions:
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_test, y_pred)

    # Menyimpan hasil evaluasi
    results[activation] = {'MSE': mse, 'RMSE': rmse, 'R2': r2}

    print(f"Model dengan {activation} - MSE: {mse}, RMSE: {rmse}, R²: {r2}")

"""### Visualisasi Prediksi vs Aktual"""

# Prediksi masing-masing model
y_pred_lr = lr_model.predict(X_test)
y_pred_boost = gb_model.predict(X_test)
y_pred_ann = ann_model.predict(X_test).flatten()

# Plot
plt.figure(figsize=(18, 5))

# Linear Regression
plt.subplot(1, 3, 1)
plt.scatter(y_test, y_pred_lr, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.title("Linear Regression")
plt.xlabel("Aktual")
plt.ylabel("Prediksi")
plt.grid(True)

# Boosting
plt.subplot(1, 3, 2)
plt.scatter(y_test, y_pred_boost, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.title("Boosting")
plt.xlabel("Aktual")
plt.ylabel("Prediksi")
plt.grid(True)

# ANN
plt.subplot(1, 3, 3)
plt.scatter(y_test, y_pred_ann, alpha=0.5)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.title("ANN")
plt.xlabel("Aktual")
plt.ylabel("Prediksi")
plt.grid(True)

plt.tight_layout()
plt.show()

"""**Kesimpulan Evaluasi Model**

Berdasarkan hasil MSE, RMSE, dan R²:

1. Linear Regression (LR):
  - Nilai MSE sangat kecil (1.12e-05), RMSE juga kecil (0.00334), dan R² sangat tinggi (0.9955), menunjukkan bahwa model ini mampu menangkap pola data dengan sangat baik.
  - Pada scatter plot, titik-titik prediksi hampir seluruhnya menempel di garis merah (garis ideal).
  - Model ini paling akurat dan stabil dibandingkan model lain.

2. Gradient Boosting Regressor (GBR):
  - MSE sebesar 0.00024, RMSE 0.0155, dan R² 0.9028, menunjukkan bahwa prediksi masih cukup akurat tetapi lebih menyebar dibandingkan linear regression.
  - Pada scatter plot, prediksi mulai terlihat tersebar di sekitar garis merah.
  - Model ini memiliki performa yang lebih rendah dibandingkan model lain.

3. Artificial Neural Network (ANN):
  - Semua fungsi aktivasi (relu, tanh, leaky_relu) menghasilkan nilai MSE: 0.000368, RMSE: 0.0192, dan R²: 0.8515, menunjukkan kinerja yang stabil tetapi lebih lemah dibanding dua model sebelumnya.
  - Scatter plot ANN menunjukkan prediksi yang lebih menyebar dari garis ideal dibandingkan GBR dan Linear Regression.
  - ANN menunjukkan performa yang baik, meskipun tidak mengungguli Linear Regression.

## Kesimpulan

**Kesimpulan Akhir**:

- Semua model (Linear Regression, ANN, dan Boosting) menunjukkan kesalahan prediksi yang rendah dan stabil antara data training dan testing. Artinya tidak terjadi overfitting.

- Linear Regression punya performa terbaik dengan MSE terkecil (1.12e-05), RMSE terkecil (0.00334), dan R² tertinggi (0.9955).

- Perbedaan performa antar model relatif kecil, namun Linear Regression secara konsisten lebih unggul.

- Berdasarkan evaluasi MSE, RMSE, dan R², Linear Regression dipilih sebagai model terbaik untuk kasus prediksi banjir ini.
"""